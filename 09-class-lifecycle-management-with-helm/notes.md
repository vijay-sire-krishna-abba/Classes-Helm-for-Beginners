Let's talk about lifecycle management with Helm. Now lifecycle management can sound like a fancy technical term that's too abstract to understand at first glance. So let's translate it into plain English by taking a look at some practical examples. Now, each time we pull in a chart and install it, a release is created. As discussed in the previous lessons, a release is somewhat similar to an app. But more specifically, it represents a package or a collection of Kubernetes objects. Now since Helm knows what Kubernetes objects belong to each release, it can do things like upgrades, downgrades or uninstalls without touching objects that might belong to other releases. So each release can be managed independently, even if they're all based on the same chart. Now let's just create a new release and discuss this as we go along. So we'll install a pretty old version of this NGINX chart. By the way, you can pass in a specific version of a Helm chart to install using the version option in the install command like this. We now have an NGINX release, plainly called NGINX release. And now imagine two months go by, which is a long time for any piece of software, but especially for a website, a lot of security vulnerabilities get discovered and they need to be patched up. Now our NGINX hosted website may have many objects in our Kubernetes cluster. When we upgrade the Pods running NGINX. Maybe we also need to make some changes to other Kubernetes objects. For example, the newer version of NGINX may require a new environment variable to be set or new secret to be created, which requires changing configuration objects and other files part of the manifest files. But it may be hard to keep track of all pieces that need to be changed. Fortunately, as we said, Helm keeps track of everything associated with a release. So we don't have to upgrade our objects one by one, Helm can automatically upgrade them all with one single command. But first, let's see what version of nginx is running in our Pod, we initially have to find out the name of our nginx Pod. So we run the kubectl get Pods command to see the Pod that we created. Then we run a kubectl describe Pod command to see more details about the image. And we see that it's running nginx version 1.19.2. So that's pretty old. Now let's see a Helm upgrade in action. The command is rather simple. So we just tell Helm what release we want to upgrade. And then specify the chart that this release is based on. So we now run the Helm upgrade command to upgrade the nginx release. So revision one is now replaced by revision two. Note the revision number in the output of the Helm upgrade command. So did the Helm upgrade command really do its job? Let's check. In the upgrade process, the old pod gets destroyed and a new one gets created. So we need to get the name of the new one. So we follow the same Helm process again and get the new pod name, then run a describe on it. And we see the new version which is nginx 1.21.4. So there you have it, we just went through the so-called lifecycle management with Helm, a release can exist for months or years. And Helm can manage its lifecycle in many ways by keeping track of its current state, previous states and bringing it into future states. So in this case, we brought the release into a future state by upgrading it. But Helm kept a record of the previous state too, we noticed the revision number changing to two. So the previous state would be revision one. Now how does that help us? Let's take a look at our releases, run the Helm list command to list the current releases. And we have our nginx release listed, we see the current revision number which happens to be two. In this case, we know what the previous revision was and what the current one is. But say we work in a big team and lots of people manage their releases. This output doesn't really tell us what happened. So how do we dig deeper? Run the Helm history command to see more details about a particular release. This is a lot more helpful, we can clearly see a lot of useful things. What chart version was or is used in each revision, what app version was or is used in each revision? What action actually created that revision? Was it an install, an upgrade, or a rollback? So this paints a clear picture of the stages our release went through its lifecycle history. Now let's assume this upgrade did something that we don't like. Helm's lifecycle management allows for another cool thing called rollback. This lets us return a release to a previous state. So in this case, we want to return to revision one. So in this case, we run the command Helm rollback nginx release and specify the revision number that we want to roll back to. And that is revision one. Now when you do that, remember Helm reverts all configuration to how it was previously in revision one. But technically, it does not go back to revision one. Instead, it creates a new revision tree with a similar configuration as in revision one. So if you list Helm revisions, with the Helm history command, now you will see that there are three versions with revision one and two having the same chart and the app versions and there is a note in the description that says it's a rollback to revision one. It's worth mentioning that we chose nginx here as it's simple to upgrade. But there will be Kubernetes packages that may require a few extra steps to upgrade. For example, if we had tried to upgrade the previous WordPress release that we created, we would have got this output. Now that's not to say that this is a problem. It can be easily solved by adding some more parameters to the command line as instructed in the text. But why does this happen? In this case, Helm cannot upgrade everything without having access to some administrative passwords. It needs administrative access to the database and to the WordPress website itself, so that it can get permissions to make necessary changes. It's also worth mentioning that all the rollbacks are very similar to a backup restore feature, it doesn't cover file or directory data that may be created by our applications. Instead, Helm backs up and restores the declarations or manifest files of our Kubernetes objects. So for things that use persistent volumes, or other forms of persistent data, or something that is external, maybe like an external database, the rollback won't restore that data to, for example, imagine your rollback MySQL database server, the MySQL Pods will be restored to their previous states, software versions used, and so on. But the actual database, its data will remain the same, its data is not going to be backed up or restored. So there are options available to take consistent backups of databases before upgrading charts, or even to roll back or restore databases. But they're done using what is known as Chart Hooks, which we will discuss later in this course. Well, that's all for now, head over to the labs and get some hands-on practice.